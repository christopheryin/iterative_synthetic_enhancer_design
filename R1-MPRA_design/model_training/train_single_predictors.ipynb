{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lG8XdYrvlmK2"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, GlobalMaxPooling1D, concatenate, ReLU\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, LSTM, ConvLSTM2D, GRU, BatchNormalization, LocallyConnected2D, Permute\n",
    "from tensorflow.keras.layers import Concatenate, Reshape, Softmax, Conv2DTranspose, Embedding, Multiply\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras.losses\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# import isolearn.keras as iso\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import isolearn.io as isoio\n",
    "# import isolearn.keras as isol\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import colors\n",
    "\n",
    "# import editdistance\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2AFmW53ClmLK",
    "outputId": "17985446-9df3-432a-8afa-fccf8c9bb405",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (40268, 145, 4)\n",
      "y_train.shape = (40268, 2)\n",
      "\n",
      "x_valid.shape = (10000, 145, 4)\n",
      "y_valid.shape = (10000, 2)\n",
      "\n",
      "x_test.shape = (10000, 145, 4)\n",
      "y_test.shape = (10000, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct data features\n",
    "\n",
    "# location of filtered Sharpr-MPRA data (R0-MPRA)\n",
    "base_dir = '/content/drive/MyDrive/Colab Notebooks/'\n",
    "\n",
    "promoter = \"minp\"\n",
    "\n",
    "cell_line_1 = \"hepg2\"\n",
    "cell_line_2 = \"k562\"\n",
    "\n",
    "x_train = np.load(base_dir + \"sharpr_cached_\" + promoter + \"_\" + cell_line_1 + \"_\" + cell_line_2 + \"minlogfold-2.4_minDNA200\" + \"_x_train.npy\")\n",
    "x_valid = np.load(base_dir +\"sharpr_cached_\" + promoter + \"_\" + cell_line_1 + \"_\" + cell_line_2 + \"minlogfold-2.4_minDNA200\" + \"_x_valid.npy\")\n",
    "x_test = np.load(base_dir +\"sharpr_cached_\" + promoter + \"_\" + cell_line_1 + \"_\" + cell_line_2 + \"minlogfold-2.4_minDNA200\" + \"_x_test.npy\")\n",
    "\n",
    "y_train = np.load(base_dir +\"sharpr_cached_\" + promoter + \"_\" + cell_line_1 + \"_\" + cell_line_2 + \"minlogfold-2.4_minDNA200\" + \"_y_train.npy\")\n",
    "y_valid = np.load(base_dir +\"sharpr_cached_\" + promoter + \"_\" + cell_line_1 + \"_\" + cell_line_2 + \"minlogfold-2.4_minDNA200\" + \"_y_valid.npy\")\n",
    "y_test = np.load(base_dir +\"sharpr_cached_\" + promoter + \"_\" + cell_line_1 + \"_\" + cell_line_2 + \"minlogfold-2.4_minDNA200\" + \"_y_test.npy\")\n",
    "\n",
    "# remove unnecessary dimension\n",
    "x_train = x_train[:,0,:,:]\n",
    "x_valid = x_valid[:,0,:,:]\n",
    "x_test = x_test[:,0,:,:]\n",
    "    \n",
    "print(\"x_train.shape = \" + str(x_train.shape))\n",
    "print(\"y_train.shape = \" + str(y_train.shape))\n",
    "print(\"\")\n",
    "\n",
    "print(\"x_valid.shape = \" + str(x_valid.shape))\n",
    "print(\"y_valid.shape = \" + str(y_valid.shape))\n",
    "print(\"\")\n",
    "\n",
    "print(\"x_test.shape = \" + str(x_test.shape))\n",
    "print(\"y_test.shape = \" + str(y_test.shape))\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bxdBm6KhPGFl"
   },
   "outputs": [],
   "source": [
    "# define R1-MPRA model architecture\n",
    "def get_pat_model(n_filters,filt_sizes,n_dense,dropout_rate):\n",
    "  sequence_input = Input(shape=(145, 4),name=\"pat_input\")\n",
    "\n",
    "  convs = [None]*len(filt_sizes)\n",
    "\n",
    "  for i in range(len(filt_sizes)):\n",
    "    conv1           = Conv1D(n_filters, filt_sizes[i], padding='same', activation='linear', name = \"pat_conv_\" + str(i))(sequence_input)\n",
    "    batchnorm1      = BatchNormalization(axis=-1,name = \"pat_batchnorm_\" + str(i))(conv1)\n",
    "    relu1           = Activation('relu',name = \"pat_relu_\" + str(i))(batchnorm1)\n",
    "    convs[i]        = Dropout(dropout_rate,name = \"pat_dropout_\" + str(i))(GlobalMaxPooling1D(name = \"pat_pool_\" + str(i))(relu1))\n",
    "\n",
    "  concat1           = concatenate(convs,name=\"pat_concat_layer\")\n",
    "\n",
    "  dense           = Dense(n_dense,activation='relu',name=\"pat_dense\")(concat1)\n",
    "  output          = Dense(2,activation='linear',name=\"pat_output\")(dense)  # 0 - HepG2, 1 - K562\n",
    "\n",
    "  model = Model(inputs=sequence_input,outputs=output)\n",
    "  model.compile(optimizer=tensorflow.keras.optimizers.Adam(lr=0.0002, beta_1=0.9, beta_2=0.999),\n",
    "                loss=\"mse\")\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Qhk37AIllmLQ",
    "outputId": "b63d4825-99b3-42e9-affd-902f1640fe02",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train conv model\n",
    "\n",
    "n_models = 10\n",
    "n_epochs = 60\n",
    "batch_size = 64\n",
    "\n",
    "for model_ix in range(n_models) :\n",
    "\n",
    "    # keep this line otherwise training models in loop slows down\n",
    "    K.clear_session() \n",
    "\n",
    "    model_name = \"wide_\" + str(model_ix)\n",
    "\n",
    "    print(\"Training model '\" + model_name + \"'\")\n",
    "\n",
    "    conv_model = get_pat_model(600,[25,11,7],64,0.075)\n",
    "    \n",
    "    callbacks =[\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            min_delta=1e-6,\n",
    "            patience=8,\n",
    "            verbose=True,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    train_history = conv_model.fit(\n",
    "        [x_train],\n",
    "        [y_train],\n",
    "        shuffle=True,\n",
    "        epochs=n_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(\n",
    "            [x_valid],\n",
    "            [y_valid]\n",
    "        ),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # Save model and weights\n",
    "    save_dir = 'saved_models'\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    model_path = os.path.join(save_dir, model_name + '.h5')\n",
    "    conv_model.save(model_path)\n",
    "    print('Saved trained model at %s ' % model_path)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_ensembles",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
